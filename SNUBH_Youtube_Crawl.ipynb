{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "def check_comment_count_is_zero(html_source, css_selector):\n",
    "    is_comment_count_zero = False\n",
    "    \n",
    "    soup = BeautifulSoup(html_source, 'lxml')\n",
    "    datas = soup.select(css_selector)\n",
    "    print(datas)\n",
    "    if len(datas) > 0:\n",
    "        comment_count_data = datas[0]\n",
    "        \n",
    "        if comment_count_data.text == \"0 Comments\":\n",
    "            is_comment_count_zero = True\n",
    "            \n",
    "    return is_comment_count_zero\n",
    "\n",
    "def scroll(driver, height=700):\n",
    "    driver.execute_script(f\"window.scrollTo(0, {height});\")\n",
    "\n",
    "def scroll_page(driver, target='essential'):\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    if target == 'essential':\n",
    "        for _ in range(3):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "            time.sleep(1.0)\n",
    "            new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            last_page_height = new_page_height\n",
    "            \n",
    "    elif target == 'comment':\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "            \n",
    "            time.sleep(2.0)\n",
    "            \n",
    "            new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            \n",
    "            if new_page_height == last_page_height:\n",
    "                break\n",
    "                \n",
    "            last_page_height = new_page_height\n",
    "    \n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_url_title_in_html_source(html_source, css_selector):\n",
    "    titles, urls = [], []\n",
    "    \n",
    "    soup = BeautifulSoup(html_source, 'lxml')\n",
    "    \n",
    "    datas = soup.select(css_selector)\n",
    "    \n",
    "    for data in datas:\n",
    "        title = data.text.replace('\\n', '')\n",
    "        url = \"https://www.youtube.com\" + data.get('href')\n",
    "        \n",
    "        titles.append(title)\n",
    "        urls.append(url)\n",
    "        \n",
    "    return titles, urls\n",
    "\n",
    "        \n",
    "def get_channel_video_url_list(channel_url):\n",
    "    titles = []\n",
    "    urls = []\n",
    "    \n",
    "    driver = wd.Chrome(ChromeDriverManager().install())\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    driver.get(channel_url)\n",
    "    \n",
    "    driver = scroll_page(driver=driver)\n",
    "        \n",
    "    html_source = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    url_title_css_selector = \"#a.yt-simple-endpoint.focus-on-expand.style-scope.ytd-rich-grid-media\"\n",
    "    \n",
    "    titles, urls = get_url_title_in_html_source(\n",
    "        html_source=html_source, \n",
    "        css_selector=url_title_css_selector\n",
    "    )\n",
    "    return titles, urls\n",
    "\n",
    "def crawl_youtube_page_html_sources(urls, driver_dir):\n",
    "    html_sources = []\n",
    "\n",
    "    for idx in range(len(urls)):\n",
    "        driver = wd.Chrome(service=Service(driver_dir))\n",
    "        driver.maximize_window()\n",
    "        driver.get(urls[idx]['url'])\n",
    "        \n",
    "        time.sleep(2.0)\n",
    "        # Expand detail\n",
    "        click_detail = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#expand')))\n",
    "        click_detail.click()\n",
    "        scroll(driver)\n",
    "        \n",
    "        comment_css_selector = \"yt-formatted-string.count-text.style-scope.ytd-comments-header-renderer\"\n",
    "        \n",
    "        html_source = driver.page_source\n",
    "        \n",
    "        # is_comment_count_zero = check_comment_count_is_zero(\n",
    "        #     html_source=html_source, css_selector=comment_css_selector\n",
    "        # )\n",
    "        \n",
    "        # if not is_comment_count_zero:\n",
    "        driver = scroll_page(driver=driver)\n",
    "\n",
    "        html_source = driver.page_source\n",
    "        html_sources.append(html_source)\n",
    "        driver.quit()\n",
    "    \n",
    "    return html_sources\n",
    "\n",
    "def post_processing_text(text):\n",
    "    return text.replace('\\n', '').replace('\\t', '').replace('                ','') if text is not None else \"\"\n",
    "\n",
    "def pack_space(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def divide_watch_shorts(titles, urls):\n",
    "    watch_url, shorts_url = [], []\n",
    "    \n",
    "    for title, url in zip(titles, urls):\n",
    "        url_type = url.split(\"/\")[3].split(\"?\")[0]\n",
    "        \n",
    "        if url_type == \"watch\":\n",
    "            watch_url.append({\n",
    "                \"title\": title, \n",
    "                \"url\": url\n",
    "            })\n",
    "        elif url_type == \"watch\":\n",
    "            shorts_url.append({\n",
    "                \"title\": title, \n",
    "                \"url\": url\n",
    "            })\n",
    "            \n",
    "    return watch_url, shorts_url\n",
    "\n",
    "def get_title_view_date(url_dict ,html_source):\n",
    "    video_info_result_dict = {\n",
    "        \"title\": url_dict['title'], \n",
    "        \"video_url\": url_dict['url'],\n",
    "        \"comment\": []\n",
    "    }\n",
    "\n",
    "    title_selector = \"#title > h1 > yt-formatted-string\"\n",
    "    view_selector = \"#info > span:nth-child(1)\"\n",
    "    date_selector = \"#info > span:nth-child(3)\"\n",
    "    # description_selector = \"#description-inline-expander > yt-attributed-string > span > span:nth-child(6)\"\n",
    "    no_comment_selector = \"#count > yt-formatted-string > span:nth-child(1)\"\n",
    "    soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "    title_list = soup.select(title_selector)\n",
    "    view_count_list = soup.select(view_selector)\n",
    "    date_list = soup.select(date_selector)\n",
    "    no_of_comment_list = soup.select(no_comment_selector)\n",
    "    \n",
    "    for title, view_count, date in zip(title_list, view_count_list, date_list):\n",
    "        print(f\"title: {title.text}, views: {view_count.text}, date:{date.text}\")\n",
    "        \n",
    "        title = title.text\n",
    "        views = view_count.text.split(' ')[0]\n",
    "        dates = date.text\n",
    "        # num_comment = no_of_comment.text\n",
    "        \n",
    "        video_info_dict = {\"title\":title, 'views': views, 'dates': dates}\n",
    "        video_info_result_dict['comment'].append(video_info_dict)\n",
    "    \n",
    "    return video_info_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling the title, url of all videos completed!\n",
      "No. of videos: 350\n",
      "title: 무서운 급성심근경색! 살기 위해 꼭 알아야 하는 심근경색 증상 1가지 [숫자로 보는 건강], views: 1,441 views, date:Sep 14, 2023\n",
      "title: 분당서울대학교병원 라이브 건강 강좌, views: 1,374 views, date:Sep 4, 2023\n",
      "title: Pioneering Digital Healthcare: Seoul National University Bundang Hospital's Smart Medical Revolution, views: 778 views, date:Aug 28, 2023\n"
     ]
    }
   ],
   "source": [
    "def youtube_crawling(url_num):\n",
    "  driver_dir = '/Users/jyh/Downloads/chromedriver-mac-arm64/chromedriver'\n",
    "  driver = wd.Chrome(service=Service(driver_dir))\n",
    "\n",
    "  crawling_result_list = []\n",
    "  url = \"https://www.youtube.com/@snubh/videos\"\n",
    "  driver.get(url)\n",
    "\n",
    "  css_selector = \"a.yt-simple-endpoint.focus-on-expand.style-scope.ytd-rich-grid-media\"\n",
    "\n",
    "  driver = scroll_page(driver=driver, target='comment')\n",
    "  html_source = driver.page_source\n",
    "\n",
    "  # Crawling titles and urls of videos\n",
    "  titles, urls = get_url_title_in_html_source(css_selector=css_selector,  html_source=html_source)\n",
    "  print(\"Crawling the title, url of all videos completed!\")\n",
    "  print(f\"No. of videos: {len(titles)}\")\n",
    "\n",
    "  urls, shorts_url = divide_watch_shorts(titles, urls)\n",
    "\n",
    "  # Crawling page sources\n",
    "  urls = urls[:url_num]\n",
    "  html_sources = crawl_youtube_page_html_sources(urls, driver_dir)\n",
    "\n",
    "  # Crawl comments and id\n",
    "  for url_dict, html_source in zip(urls, html_sources):\n",
    "      video_info_result_dict = get_title_view_date(url_dict, html_source)\n",
    "      crawling_result_list.append(video_info_result_dict)\n",
    "\n",
    "  result_df = pd.DataFrame()\n",
    "  for i in crawling_result_list:\n",
    "    result_df = pd.concat([result_df, pd.DataFrame(i['comment'])], axis=0) \n",
    "  result_df['dates'] = pd.to_datetime(result_df['dates']).dt.strftime('%Y-%m-%d')\n",
    "  result_df['views'] = result_df['views'].str.replace(\",\",\"\").astype(int)\n",
    "  if url_num < 10:\n",
    "    result_df.to_csv('SNUBH_Youtube_crawling_test.csv')\n",
    "  else:\n",
    "    result_df.to_csv('SNUBH_Youtube_crawling.csv')\n",
    "  \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
